import asyncio

from aiogram import types
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext

import bot.constants as constants
from bot.helpers import text
from bot.helpers.generateImages.dataArray.getAllDataArrays import (
    getAllDataArrays,
)
from bot.helpers.generateImages.dataArray.getModelNameByIndex import (
    getModelNameByIndex,
)
from bot.helpers.handlers.img2video import process_video
from bot.InstanceBot import bot, router
from bot.keyboards import video_generation_keyboards
from bot.logger import logger
from bot.states import StartGenerationState
from bot.utils.handlers import appendDataToStateArray
from bot.utils.handlers.messages.rate_limiter_for_edit_message import (
    safe_edit_message,
)
from bot.utils.handlers.messages.rate_limiter_for_send_message import (
    safe_send_message,
)


# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð°Ð¶Ð°Ñ‚Ð¸Ñ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒ "ðŸ“¹ Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ'"
async def start_generateVideoFromImage(
    call: types.CallbackQuery,
    state: FSMContext,
):
    await state.clear()

    await safe_edit_message(
        call.message,
        text.SEND_IMAGES_FOR_VIDEO_GENERATION,
        reply_markup=video_generation_keyboards.img2video_done_send_images_keyboard(),
    )
    await state.set_state(StartGenerationState.send_image_for_video_generation)


# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°Ð½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð° Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°
async def get_images_for_img2video(
    message: types.Message,
    state: FSMContext,
    album: list[types.Message] = [],
):
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸
    if not message.photo and not album:
        await safe_send_message(
            text.NO_IMAGE_FOR_VIDEO_GENERATION_ERROR_TEXT,
            message,
        )
        return

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ file_id ÑÐ°Ð¼Ð¾Ð³Ð¾ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    state_data = await state.get_data()
    img2video_images_file_ids = state_data.get("img2video_images_file_ids", [])

    if not album:
        photo = message.photo[-1]
        image_file_id = photo.file_id
        img2video_images_file_ids.append(image_file_id)
    else:
        for message in album:
            photo = message.photo[-1]
            image_file_id = photo.file_id
            img2video_images_file_ids.append(image_file_id)

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð² ÑÑ‚ÐµÐ¹Ñ‚
    await state.update_data(img2video_images_file_ids=img2video_images_file_ids)

    await safe_send_message(
        text.SUCCESS_GET_IMAGES_FOR_VIDEO_GENERATION_TEXT.format(len(img2video_images_file_ids))
        if len(img2video_images_file_ids) > 1 else text.SUCCESS_GET_IMAGE_FOR_VIDEO_GENERATION_TEXT,
        message,
    )


# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð°Ð¶Ð°Ñ‚Ð¸Ñ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÑƒ "âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾" Ð´Ð»Ñ Ð¿Ñ€ÐµÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ñ ÑÐ±Ð¾Ñ€Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾
async def done_send_images_for_img2video(
    message: types.Message,
    state: FSMContext,
):
    state_data = await state.get_data()
    img2video_images_file_ids = state_data.get("img2video_images_file_ids", [])

    if len(img2video_images_file_ids) == 0:
        await safe_send_message(
            text.NO_IMAGES_FOR_VIDEO_GENERATION_ERROR_TEXT,
            message,
        )
        return

    # Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ð¿Ð°Ð¿ÐºÑƒ
    temp_paths_for_video_generation = []
    for image_file_id in img2video_images_file_ids:
        # Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (file_id) Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ
        # Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ bot.download_file Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ
        try:
            file = await asyncio.wait_for(
                bot.get_file(image_file_id),
                timeout=30,
            )
        except TimeoutError:
            await safe_send_message(
                "â° Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Telegram Ð¸ÑÑ‚ÐµÐºÐ»Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.",
                message,
            )
            raise TimeoutError(
                "Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Telegram Ð¸ÑÑ‚ÐµÐºÐ»Ð¾.",
            )

        file_path = file.file_path
        temp_path = f"{constants.TEMP_IMAGE_FILES_DIR}/{image_file_id}.jpg"
        temp_paths_for_video_generation.append(temp_path)

        try:
            await asyncio.wait_for(
                bot.download_file(file_path, temp_path),
                timeout=60,
            )
        except TimeoutError:
            await safe_send_message(
                "â° Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Telegram Ð¸ÑÑ‚ÐµÐºÐ»Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.",
                message,
            )
            raise TimeoutError(
                "Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Telegram Ð¸ÑÑ‚ÐµÐºÐ»Ð¾.",
            )

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð² ÑÑ‚ÐµÐ¹Ñ‚
    await state.update_data(temp_paths_for_video_generation=temp_paths_for_video_generation)

    # ÐŸÑ€Ð¾ÑÐ¸Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ð²ÐµÑÑ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾
    await state.set_state(None)

    message_text = text.WRITE_PROMPT_FOR_VIDEO_GENERATION_FROM_IMAGE_TEXT \
        if len(temp_paths_for_video_generation) ==  1 \
        else text.WRITE_PROMPT_FOR_MULTI_VIDEO_GENERATION_FROM_IMAGE_TEXT.format(len(temp_paths_for_video_generation))

    await safe_send_message(
        message_text,
        message,
    )

    await state.set_state(
        StartGenerationState.write_prompt_for_img2video,
    )


# Ð¥ÐµÐ½Ð´Ð»ÐµÑ€ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
async def handle_prompt_for_img2video(
    message: types.Message,
    state: FSMContext,
):
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
    prompt = message.text

    await state.update_data(prompt_for_img2video=prompt)

    state_data = await state.get_data()
    temp_paths_for_video_generation = state_data.get(
        "temp_paths_for_video_generation", []
    )

    message_text = text.ASK_FOR_MODEL_NAME_FOR_VIDEO_GENERATION_FROM_IMAGE_TEXT \
        if len(temp_paths_for_video_generation) == 1 \
        else text.GET_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT.format(len(temp_paths_for_video_generation))

    await safe_send_message(
        message_text,
        message,
    )

    await state.set_state(
        StartGenerationState.ask_for_model_index_for_img2video,
    )


# Ð¥ÐµÐ½Ð´Ð»ÐµÑ€ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð²Ð²Ð¾Ð´Ð° Ð¸Ð¼ÐµÐ½Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾
async def handle_model_index_for_video_generation_from_image(
    message: types.Message,
    state: FSMContext,
):
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· ÑÑ‚ÐµÐ¹Ñ‚Ð°
    state_data = await state.get_data()

    temp_paths_for_video_generation = state_data.get(
        "temp_paths_for_video_generation",
    )

    prompt = state_data.get(
        "prompt_for_img2video",
    )

    model_indexes = []

    if len(temp_paths_for_video_generation) == 1:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        try:
            model_index = int(message.text)
            model_indexes.append((1, model_index))
        except Exception as e:
            logger.error(f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
            await safe_send_message(
                text.WRONG_MODEL_INDEX_TEXT.format(message.text),
                message,
            )
            return
    else:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        lines = message.text.strip().split('\n')
        model_indexes = []

        for line in lines:
            # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
            if not line.strip():
                continue

            # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð¿Ð¾ Ð´ÐµÑ„Ð¸ÑÑƒ
            parts = line.split('-')

            if len(parts) != 2:
                await safe_send_message(
                    text.WRONG_FORMAT_FOR_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT.format(line),
                    message,
                )
                return

            image_index = int(parts[0].strip())
            model_index = int(parts[1].strip())
            model_indexes.append((image_index, model_index))

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ð²ÐµÐ´Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð² Ñ€Ð°Ð²Ð½Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
        if len(model_indexes) != len(temp_paths_for_video_generation):
            await safe_send_message(
                text.WRONG_AMOUNT_OF_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT,
                message,
            )
            return

    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚ÐµÐ¹Ñ‚
    img2video_temp_paths_for_with_model_names = {}
    for image_index, model_index in model_indexes:
        img2video_temp_paths_for_with_model_names[getModelNameByIndex(model_index)] = \
            temp_paths_for_video_generation[image_index - 1]

    await state.update_data(img2video_temp_paths_for_with_model_names=img2video_temp_paths_for_with_model_names)

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð²ÑÐµÑ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
    all_data_arrays = getAllDataArrays()
    all_data_arrays_length = sum(len(arr) for arr in all_data_arrays)

    # Ð•ÑÐ»Ð¸ Ð¸Ð½Ð´ÐµÐºÑ ÐºÐ°ÐºÐ¾Ð¹-Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ‡Ð¸ÑÐ»Ð° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¸Ð»Ð¸ Ð¼ÐµÐ½ÑŒÑˆÐµ 1, Ñ‚Ð¾ Ð¿Ñ€Ð¾ÑÐ¸Ð¼ Ð²Ð²ÐµÑÑ‚Ð¸ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ð¸Ð½Ð´ÐµÐºÑ
    for image_index, model_index in model_indexes:
        if model_index > all_data_arrays_length or model_index < 1:
            await safe_send_message(
                text.MODEL_NOT_FOUND_TEXT.format(model_index, image_index),
            message,
            )
            return

    await state.set_state(None)

    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² Ð²Ð¸Ð´ÐµÐ¾
    tasks = [
        process_video(
            message=message,
            prompt=prompt,
            image_index=image_index,
            model_index=model_index,
            temp_paths_for_video_generation=temp_paths_for_video_generation,
        )
        for image_index, model_index in model_indexes
    ]

    # ÐŸÐ¾ÑÐ»Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ â€” Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ state
    for coro in asyncio.as_completed(tasks):
        model_name, video_path = await coro

        if not video_path:
            await safe_send_message(
                f"ÐžÑˆÐ¸Ð±ÐºÐ°: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¿ÑƒÑ‚ÑŒ Ðº Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}",
                message,
            )
            continue

        data_for_update = {f"{model_name}": video_path}
        await appendDataToStateArray(
            state,
            "generated_video_paths",
            data_for_update,
            unique_keys=("model_name",),
        )


# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¾Ð²
def hand_add():
    router.callback_query.register(
        start_generateVideoFromImage,
        lambda call: call.data == "generateVideoFromImage",
    )

    router.message.register(
        get_images_for_img2video,
        StateFilter(StartGenerationState.send_image_for_video_generation),
    )

    router.callback_query.register(
        done_send_images_for_img2video,
        lambda call: call.data == "img2video|done_send_images",
    )

    router.message.register(
        handle_prompt_for_img2video,
        StateFilter(
            StartGenerationState.write_prompt_for_img2video,
        ),
    )

    router.message.register(
        handle_model_index_for_video_generation_from_image,
        StateFilter(
            StartGenerationState.ask_for_model_index_for_img2video,
        ),
    )
