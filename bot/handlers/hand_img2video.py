import asyncio
import re

from aiogram import types
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext

import bot.constants as constants
from bot.helpers import text
from bot.helpers.generateImages.dataArray.check_model_index_is_exist import (
    check_model_index_is_exist,
)
from bot.helpers.generateImages.dataArray.get_all_model_indexes import (
    get_all_model_indexes,
)
from bot.helpers.generateImages.dataArray.get_model_name_by_index import (
    get_model_name_by_index,
)
from bot.helpers.generateImages.dataArray.getAllDataArrays import (
    getAllDataArrays,
)
from bot.helpers.handlers.img2video import process_video
from bot.InstanceBot import bot, img2video_router
from bot.keyboards import video_generation_keyboards
from bot.logger import logger
from bot.states import StartGenerationState
from bot.utils.handlers import appendDataToStateArray
from bot.utils.handlers.messages.rate_limiter_for_edit_message import (
    safe_edit_message,
)
from bot.utils.handlers.messages.rate_limiter_for_send_message import (
    safe_send_message,
)

PROMPT_BY_INDEX_PATTERN = re.compile(
    r"(?s)(\d+)\s*[:\-‚Äì‚Äî]\s*(.*?)\s*[:\-‚Äì‚Äî]\s*(\d+)(?=(?:\n\d+\s*[:\-‚Äì‚Äî].*?\s*[:\-‚Äì‚Äî]\s*\d+)|\Z)",
)

all_model_indexes = get_all_model_indexes()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫—É "üìπ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'"
async def start_generateVideoFromImage(
    call: types.CallbackQuery,
    state: FSMContext,
):
    await state.clear()

    await safe_edit_message(
        call.message,
        text.SEND_IMAGES_FOR_VIDEO_GENERATION,
        reply_markup=video_generation_keyboards.img2video_done_send_images_keyboard(),
    )
    await state.set_state(StartGenerationState.send_image_for_video_generation)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏—Å—ã–ª–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∏ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø—Ä–∏—Å—ã–ª–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞
async def get_images_for_img2video(
    message: types.Message,
    state: FSMContext,
    album: list[types.Message] = [],
):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
    if not message.photo and not album:
        await safe_send_message(
            text.NO_IMAGE_FOR_VIDEO_GENERATION_ERROR_TEXT,
            message,
        )
        return

    # –ü–æ–ª—É—á–∞–µ–º file_id —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    state_data = await state.get_data()
    img2video_images_file_ids = state_data.get("img2video_images_file_ids", [])

    if not album:
        if message.photo:
            photo = message.photo[-1]
            image_file_id = photo.file_id
            img2video_images_file_ids.append(image_file_id)
    else:
        for message in album:
            if message.photo:
                photo = message.photo[-1]
                image_file_id = photo.file_id
                img2video_images_file_ids.append(image_file_id)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –≤ —Å—Ç–µ–π—Ç
    await state.update_data(img2video_images_file_ids=img2video_images_file_ids)

    await safe_send_message(
        text.SUCCESS_GET_IMAGES_FOR_VIDEO_GENERATION_TEXT.format(len(img2video_images_file_ids))
        if len(img2video_images_file_ids) > 1 else text.SUCCESS_GET_IMAGE_FOR_VIDEO_GENERATION_TEXT,
        message,
        reply_markup=video_generation_keyboards.img2video_done_send_images_keyboard(),
    )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫—É "‚úÖ –ì–æ—Ç–æ–≤–æ" –¥–ª—è –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è —Å–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ
async def done_send_images_for_img2video(
    call: types.CallbackQuery,
    state: FSMContext,
):
    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–æ–π
    try:
        await call.message.delete()
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ: {e}")

    state_data = await state.get_data()
    img2video_images_file_ids = state_data.get("img2video_images_file_ids", [])

    if len(img2video_images_file_ids) == 0:
        await safe_send_message(
            text.NO_IMAGES_FOR_VIDEO_GENERATION_ERROR_TEXT,
            call.message,
        )
        return

    # –°–∫–∞—á–∏–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É
    temp_paths_for_video_generation = []
    for image_file_id in img2video_images_file_ids:
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (file_id) –∏ –ø–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        # –î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º bot.download_file –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        try:
            file = await asyncio.wait_for(
                bot.get_file(image_file_id),
                timeout=30,
            )
        except TimeoutError:
            await safe_send_message(
                "‚è∞ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ Telegram –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                call.message,
            )
            raise TimeoutError(
                "–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ Telegram –∏—Å—Ç–µ–∫–ª–æ.",
            )

        file_path = file.file_path
        temp_path = f"{constants.TEMP_IMAGE_FILES_DIR}/{image_file_id}.jpg"
        temp_paths_for_video_generation.append(temp_path)

        try:
            await asyncio.wait_for(
                bot.download_file(file_path, temp_path),
                timeout=60,
            )
        except TimeoutError:
            await safe_send_message(
                "‚è∞ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ Telegram –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                call.message,
            )
            raise TimeoutError(
                "–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ Telegram –∏—Å—Ç–µ–∫–ª–æ.",
            )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –≤ —Å—Ç–µ–π—Ç
    await state.update_data(temp_paths_for_video_generation=temp_paths_for_video_generation)

    # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ, —Å—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
    if len(temp_paths_for_video_generation) == 1:
        await state.set_state(StartGenerationState.write_single_prompt_for_img2video)
        
        await safe_send_message(
            text.WRITE_PROMPT_FOR_VIDEO_GENERATION_FROM_IMAGE_TEXT,
            call.message,
        )
    else:
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–æ, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å —Ç–∏–ø –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞
        await state.set_state(None)

        await safe_send_message(
            text.CHOOSE_WRITE_PROMPT_TYPE_SUCCESS_TEXT,
            call.message,
            reply_markup=video_generation_keyboards.choose_prompt_type_keyboard(),
        )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Ç–∏–ø–∞ –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è img2video
async def choose_prompt_type_for_img2video(
    call: types.CallbackQuery,
    state: FSMContext,
):

    prompt_type = call.data.split("|")[2]  # "one" –∏–ª–∏ "multi"
    
    if prompt_type == "one":
        # –û–¥–∏–Ω –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
        state_data = await state.get_data()
        temp_paths_for_video_generation = state_data.get("temp_paths_for_video_generation", [])

        message_text = text.WRITE_PROMPT_FOR_VIDEO_GENERATION_FROM_IMAGE_TEXT \
            if len(temp_paths_for_video_generation) == 1 \
            else text.WRITE_PROMPT_FOR_MULTI_VIDEO_GENERATION_FROM_IMAGE_TEXT.format(len(temp_paths_for_video_generation))
        
        logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞: {message_text}")
        
        await call.message.edit_text(message_text, reply_markup=None)
        await state.set_state(StartGenerationState.write_single_prompt_for_img2video)
    else:
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        await start_multi_prompt_input_mode_for_img2video(call, state)


# –ó–∞–ø—É—Å–∫ —Ä–µ–∂–∏–º–∞ –≤–≤–æ–¥–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è img2video
async def start_multi_prompt_input_mode_for_img2video(
    callback: types.CallbackQuery,
    state: FSMContext,
):
    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–æ–π
    try:
        await callback.message.delete()
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ: {e}")

    await state.set_state(StartGenerationState.collecting_prompt_parts_for_img2video)
    await state.update_data(
        prompt_chunks=[],
    )

    await safe_send_message(
        text.WRITE_MULTI_PROMPTS_FOR_IMG2VIDEO,
        callback,
        reply_markup=video_generation_keyboards.img2video_done_typing_keyboard(),
    )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–≤–æ–¥–∞ —á–∞—Å—Ç–µ–π –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è img2video
async def handle_chunk_input_for_img2video(message: types.Message, state: FSMContext):
    logger.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–≤–æ–¥ –≤ handle_chunk_input_for_img2video")
    
    data = await state.get_data()
    chunks = data.get("prompt_chunks", [])
    msg = message.text.strip()

    if not msg:
        await safe_send_message(
            text.EMPTY_PROMPT_TEXT,
            message,
        )
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç "‚Ññ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –ø—Ä–æ–º–ø—Ç - ‚Ññ –º–æ–¥–µ–ª–∏"
    matches = PROMPT_BY_INDEX_PATTERN.findall(msg)
    if matches:
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω —Ñ–æ—Ä–º–∞—Ç "‚Ññ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –ø—Ä–æ–º–ø—Ç - ‚Ññ –º–æ–¥–µ–ª–∏", –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        for image_index_str, prompt, model_index_str in matches:
            model_index = int(model_index_str)
            
            if not check_model_index_is_exist(model_index):
                await safe_send_message(
                    text.MODEL_NOT_FOUND_TEXT.format(model_index, all_model_indexes),
                    message,
                )
                return

    chunks.append(msg)
    await state.update_data(
        prompt_chunks=chunks,
        last_user_id=message.from_user.id,
        last_chat_id=message.chat.id,
        last_message_id=message.message_id,
    )

    await safe_send_message(
        text.MESSAGE_IS_SUCCESFULLY_DONE,
        message,
        reply_markup=video_generation_keyboards.img2video_done_typing_keyboard(),
    )


# –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è img2video
async def finish_prompt_input_for_img2video(
    callback: types.CallbackQuery,
    state: FSMContext,
):
    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–æ–π
    try:
        await callback.message.delete()
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ: {e}")

    data = await state.get_data()
    full_text = "\n".join(data.get("prompt_chunks", []))
    prompt_chunks = data.get("prompt_chunks", [])
    if not prompt_chunks:
        await safe_send_message(
            "‚ùóÔ∏è–í—ã –Ω–µ –≤–≤–µ–ª–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞.",
            callback.message,
        )
        return

    user_id = data.get("last_user_id") or callback.from_user.id
    chat_id = data.get("last_chat_id") or callback.message.chat.id

    await safe_edit_message(
        callback.message,
        "üß† –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–ª–∏–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç...",
    )
    
    try:
        fake_message = types.Message(
            message_id=callback.message.message_id,
            date=callback.message.date,
            chat=types.Chat(id=chat_id, type="private"),
            from_user=callback.from_user,
            text=full_text,
        )
    except Exception as e:
        logger.exception(
            f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ finish_prompt_input_for_img2video –¥–ª—è user_id={user_id}, chat_id={chat_id}",
        )
        await safe_edit_message(
            callback.message,
            "‚ùóÔ∏è–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–º–ø—Ç–∞.",
        )
        return

    await process_multi_prompts_for_img2video(
        message=fake_message,
        state=state,
        text_input=full_text,
    )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è img2video
async def process_multi_prompts_for_img2video(
    message: types.Message,
    state: FSMContext,
    text_input: str = None,
):
    text_input = text_input or message.text.strip()
    matches = PROMPT_BY_INDEX_PATTERN.findall(text_input)

    if not matches:
        await safe_send_message(
            text=text.WRONG_FORMAT_TEXT,
            message=message,
        )
        return

    state_data = await state.get_data()
    temp_paths_for_video_generation = state_data.get("temp_paths_for_video_generation", [])
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if len(matches) != len(temp_paths_for_video_generation):
        await safe_send_message(
            f"‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π ({len(matches)}) –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({len(temp_paths_for_video_generation)})!",
            message,
    )
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    for image_index_str, prompt, model_index_str in matches:
        image_index = int(image_index_str)
        model_index = int(model_index_str)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if image_index < 1 or image_index > len(temp_paths_for_video_generation):
            await safe_send_message(
                f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_index}. –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 1-{len(temp_paths_for_video_generation)}",
                message,
            )
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if not check_model_index_is_exist(model_index):
            await safe_send_message(
                text.MODEL_NOT_FOUND_TEXT.format(model_index, all_model_indexes),
                message,
            )
            return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    img2video_data = []
    for image_index_str, prompt, model_index_str in matches:
        image_index = int(image_index_str)
        model_index = int(model_index_str)
        img2video_data.append({
            'image_index': image_index,
            'prompt': prompt.strip(),
            'model_index': model_index,
        })

    await state.update_data(img2video_data=img2video_data)

    # –°—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ
    await process_img2video_with_data(message, state)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –≥–æ—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
async def process_img2video_with_data(
    message: types.Message,
    state: FSMContext,
):
    state_data = await state.get_data()
    img2video_data = state_data.get("img2video_data", [])
    temp_paths_for_video_generation = state_data.get("temp_paths_for_video_generation", [])

    if not img2video_data:
        await safe_send_message(
            "‚ùå –û—à–∏–±–∫–∞: –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
            message,
        )
        return

    await state.set_state(None)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ
    # –ó–∞–¥–∞—á–∏ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –Ω–æ —Å—Ç–∞—Ä—Ç –∫–∞–∂–¥–æ–π —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π 0.5 —Å–µ–∫—É–Ω–¥—ã
    tasks = []
    for data in img2video_data:
        task = asyncio.create_task(
            process_video(
                message=message,
                prompt=data['prompt'],
                image_index=data['image_index'],
                model_index=data['model_index'],
                temp_paths_for_video_generation=temp_paths_for_video_generation,  # –ü–µ—Ä–µ–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π
            )
        )
        tasks.append(task)
        await asyncio.sleep(0.5)

    # –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º state
    for coro in asyncio.as_completed(tasks):
        model_name, video_path = await coro

        if not video_path:
            await safe_send_message(
                f"–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}",
                message,
            )
            continue

        data_for_update = {f"{model_name}": video_path}
        await appendDataToStateArray(
            state,
            "generated_video_paths",
            data_for_update,
            unique_keys=("model_name",),
        )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–≤–æ–¥–∞ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è img2video (—Å—Ç–∞—Ä—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª)
async def handle_single_prompt_for_img2video(
    message: types.Message,
    state: FSMContext,
):
    logger.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–∏–Ω –ø—Ä–æ–º–ø—Ç –≤ handle_single_prompt_for_img2video")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt = message.text

    await state.update_data(prompt_for_img2video=prompt)

    state_data = await state.get_data()
    temp_paths_for_video_generation = state_data.get(
        "temp_paths_for_video_generation", []
    )

    message_text = text.ASK_FOR_MODEL_NAME_FOR_VIDEO_GENERATION_FROM_IMAGE_TEXT \
        if len(temp_paths_for_video_generation) == 1 \
        else text.GET_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT.format(len(temp_paths_for_video_generation))

    logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –º–æ–¥–µ–ª–∏: {message_text}")

    await safe_send_message(
        message_text,
        message,
    )

    await state.set_state(
        StartGenerationState.ask_for_model_index_for_img2video,
    )


# –•–µ–Ω–¥–ª–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–≤–æ–¥–∞ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ
async def handle_model_index_for_video_generation_from_image(
    message: types.Message,
    state: FSMContext,
):
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–µ–π—Ç–∞
    state_data = await state.get_data()

    temp_paths_for_video_generation = state_data.get(
        "temp_paths_for_video_generation",
    )

    prompt = state_data.get(
        "prompt_for_img2video",
    )

    model_indexes = []

    if len(temp_paths_for_video_generation) == 1:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏
        try:
            model_index = int(message.text)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if not check_model_index_is_exist(model_index):
                await safe_send_message(
                    text.MODEL_NOT_FOUND_TEXT.format(model_index, all_model_indexes),
                    message,
                )
                return

            model_indexes.append((1, model_index))
        except ValueError:
            logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –º–æ–¥–µ–ª–∏: {message.text}")
            await safe_send_message(
                text.WRONG_MODEL_INDEX_TEXT.format(message.text),
                message,
            )
            return
        except Exception as e:
            logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞ –º–æ–¥–µ–ª–∏: {e}")
            await safe_send_message(
                text.WRONG_MODEL_INDEX_TEXT.format(message.text),
                message,
            )
            return
    else:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        lines = message.text.strip().split('\n')
        model_indexes = []

        for line in lines:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            if not line.strip():
                continue

            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–µ—Ñ–∏—Å—É
            parts = line.split('-')

            if len(parts) != 2:
                await safe_send_message(
                    text.WRONG_FORMAT_FOR_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT.format(line),
                    message,
                )
                return

            try:
                image_index = int(parts[0].strip())
                model_index = int(parts[1].strip())
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if image_index < 1 or image_index > len(temp_paths_for_video_generation):
                    await safe_send_message(
                        f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_index}. –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 1-{len(temp_paths_for_video_generation)}",
                        message,
                    )
                    return
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                if not check_model_index_is_exist(model_index):
                    await safe_send_message(
                        text.MODEL_NOT_FOUND_TEXT.format(model_index, all_model_indexes),
                        message,
                    )
                    return
                
                model_indexes.append((image_index, model_index))
            except ValueError:
                await safe_send_message(
                    f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Å—Ç—Ä–æ–∫–µ: {line}. –û–∂–∏–¥–∞–µ—Ç—Å—è: –Ω–æ–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏",
                    message,
                )
                return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if len(model_indexes) != len(temp_paths_for_video_generation):
            await safe_send_message(
                text.WRONG_AMOUNT_OF_MODEL_INDEXES_FOR_ALL_IMAGES_TEXT,
                message,
            )
            return

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–µ–π—Ç
    img2video_temp_paths_for_with_model_names = {}
    for image_index, model_index in model_indexes:
        img2video_temp_paths_for_with_model_names[get_model_name_by_index(model_index)] = \
            temp_paths_for_video_generation[image_index - 1]

    await state.update_data(img2video_temp_paths_for_with_model_names=img2video_temp_paths_for_with_model_names)
    
    # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –∫–∞–∫–æ–π-—Ç–æ –º–æ–¥–µ–ª–∏ –±–æ–ª—å—à–µ —á–∏—Å–ª–∞ –º–æ–¥–µ–ª–µ–π –∏–ª–∏ –º–µ–Ω—å—à–µ 1, —Ç–æ –ø—Ä–æ—Å–∏–º –≤–≤–µ—Å—Ç–∏ –¥—Ä—É–≥–æ–π –∏–Ω–¥–µ–∫—Å
    for image_index, model_index in model_indexes:
        if not check_model_index_is_exist(model_index):
            await safe_send_message(
                text.MODEL_NOT_FOUND_TEXT.format(model_index, all_model_indexes),
                message,
            )
            return

    await state.set_state(None)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≤–∏–¥–µ–æ
    # –ó–∞–¥–∞—á–∏ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –Ω–æ —Å—Ç–∞—Ä—Ç –∫–∞–∂–¥–æ–π —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π 0.5 —Å–µ–∫—É–Ω–¥—ã
    tasks = []
    for image_index, model_index in model_indexes:
        task = asyncio.create_task(
            process_video(
                message=message,
                prompt=prompt,
                image_index=image_index,
                model_index=model_index,
                temp_paths_for_video_generation=temp_paths_for_video_generation,
            )
        )
        tasks.append(task)
        await asyncio.sleep(0.5)

    # –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º state
    for coro in asyncio.as_completed(tasks):
        try:
            result = await coro
            # process_video –∏–∑ img2video –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (model_name, video_path)
            if isinstance(result, tuple) and len(result) == 2:
                model_name, video_path = result
                
                if not video_path:
                    await safe_send_message(
                        f"–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}",
                        message,
                    )
                    continue

                data_for_update = {f"{model_name}": video_path}
                await appendDataToStateArray(
                    state,
                    "generated_video_paths",
                    data_for_update,
                    unique_keys=("model_name",),
                )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}")
            await safe_send_message(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {str(e)}",
                message,
            )
            continue


# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
def hand_add():
    img2video_router.callback_query.register(
        start_generateVideoFromImage,
        lambda call: call.data == "generateVideoFromImage",
    )
    img2video_router.message.register(
        get_images_for_img2video,
        StateFilter(StartGenerationState.send_image_for_video_generation),
    )
    img2video_router.callback_query.register(
        done_send_images_for_img2video,
        lambda call: call.data == "img2video|done_send_images",
    )
    img2video_router.message.register(
        handle_single_prompt_for_img2video,
        StateFilter(
            StartGenerationState.write_single_prompt_for_img2video,
        ),
    )
    img2video_router.message.register(
        handle_model_index_for_video_generation_from_image,
        StateFilter(
            StartGenerationState.ask_for_model_index_for_img2video,
        ),
    )
    # –ù–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    img2video_router.callback_query.register(
        choose_prompt_type_for_img2video,
        lambda call: call.data.startswith("img2video|prompt_type"),
    )
    img2video_router.message.register(
        handle_chunk_input_for_img2video,
        StateFilter(
            StartGenerationState.collecting_prompt_parts_for_img2video,
        ),
    )
    img2video_router.callback_query.register(
        finish_prompt_input_for_img2video,
        lambda call: call.data == "img2video|finish_prompt",
    )
