import re
import traceback

from aiogram import types
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext

from bot.helpers import text
from bot.helpers.generateImages.dataArray import (
    getAllDataArrays,
    getDataByModelName,
    getModelNameIndex,
    getModelNameByIndex
)
from bot.helpers.generateImages.generateImageBlock import generateImageBlock
from bot.helpers.handlers.messages import deleteMessageFromState
from bot.helpers.handlers.startGeneration import (
    generateImagesInHandler,
    process_image,
    regenerateImage,
)
from bot.InstanceBot import bot, router
from bot.keyboards import (
    randomizer_keyboards,
    start_generation_keyboards,
)
from bot.logger import logger
from bot.states.StartGenerationState import StartGenerationState
from bot.utils.handlers import (
    appendDataToStateArray,
)
from bot.utils.handlers.messages import (
    editMessageOrAnswer,
)
from bot.utils.handlers.messages.rate_limiter_for_send_message import (
    safe_send_message,
)

PROMPT_BY_INDEX_PATTERN = re.compile(
    r"(?s)(\d+)\s*[:\-‚Äì‚Äî]\s*(.*?)(?=(?:\n\d+\s*[:\-‚Äì‚Äî])|\Z)",
)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π
async def choose_generations_type(
    call: types.CallbackQuery,
    state: FSMContext,
):
    generations_type = call.data.split("|")[1]
    await state.update_data(generations_type=generations_type)

    if generations_type == "work":
        await editMessageOrAnswer(
            call,
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n\n"
            "üñº –ú—É–ª—å—Ç–∏–≤—ã–±–æ—Ä - –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –ø—Ä–∏—Å—ã–ª–∞–µ—Ç—Å—è 10 –Ω–∞ –≤—ã–±–æ—Ä\n"
            "‚úÖ –û–¥–∏–Ω–æ—á–Ω—ã–π - –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –ø—Ä–∏—Å—ã–ª–∞–µ—Ç—Å—è 4 –Ω–∞ –≤—ã–±–æ—Ä",
            reply_markup=start_generation_keyboards.generationModeKeyboard(),
        )
        return

    try:
        prompt_exist = bool(call.data.split("|")[2])
    except:
        prompt_exist = False

    await state.update_data(prompt_exist=prompt_exist)

    await editMessageOrAnswer(
        call,
        text.GET_GENERATIONS_SUCCESS_TEXT,
        reply_markup=start_generation_keyboards.selectSettingKeyboard(
            is_test_generation=generations_type == "test",
        ),
    )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
async def choose_generation_mode(call: types.CallbackQuery, state: FSMContext):
    mode = call.data.split("|")[1]
    if mode == "multi_select":
        await state.update_data(multi_select_mode=True)
    else:
        await state.update_data(multi_select_mode=False)
    await editMessageOrAnswer(
        call,
        "‚úÖ –¢–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –≤—ã–±—Ä–∞–Ω! –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏ –∫–∞–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±—É–¥–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:",
        reply_markup=start_generation_keyboards.selectSettingKeyboard(
            is_test_generation=False,
        ),
    )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
async def choose_setting(call: types.CallbackQuery, state: FSMContext):
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å—Ç–µ–π—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–Ω–¥–æ–º–∞–π–∑–µ—Ä–∞
    current_state_data = await state.get_data()
    variable_names_for_randomizer = current_state_data.get(
        "variable_names_for_randomizer",
        [],
    )

    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π initial_state
    initial_state = {
        "generation_step": 1,
        "prompts_for_regenerated_models": [],
        "regenerated_models": [],
        "model_indexes_for_generation": [],
        "saved_images_urls": [],
        "faceswap_generated_models": [],
        "imageGeneration_mediagroup_messages_ids": [],
        "videoGeneration_messages_ids": [],
        "process_images_steps": [],
        "upscale_progress_messages": [],
        "variable_names_for_randomizer": [],
        "generated_video_paths": [],
        "model_prompts_for_generation": [],
    }

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏ —Å —Ñ–æ—Ä–º–æ–π "randomizer_{variable_name}_values" —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º [] (–¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–Ω–¥–æ–º–∞–π–∑–µ—Ä–∞)
    for variable_name in variable_names_for_randomizer:
        key = f"randomizer_{variable_name}_values"
        initial_state[key] = []

    await state.update_data(**initial_state)

    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –º–æ–¥–µ–ª—å, —Ç–æ –ø—Ä–æ—Å–∏–º –≤–≤–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if call.data == "select_setting|specific_model":
        await editMessageOrAnswer(
            call,
            text.WRITE_MODELS_NAME_TEXT,
        )
        await state.update_data(specific_model=True)
        # –û—á–∏—â–∞–µ–º —Å—Ç–µ–π—Ç
        await state.set_state(
            StartGenerationState.write_model_name_for_generation,
        )
        return

    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –¥—Ä—É–≥–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞, —Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    setting_number = call.data.split("|")[1]
    await state.update_data(setting_number=setting_number)
    state_data = await state.get_data()
    generations_type = state_data.get("generations_type", "")
    prompt_exist = state_data.get("prompt_exist", False)
    await state.update_data(specific_model=False)

    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∞, —Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    if generations_type == "test":
        if prompt_exist:
            prompt = state_data.get("prompt_for_images", "")
            user_id = call.from_user.id
            is_test_generation = generations_type == "test"
            setting_number = setting_number

            # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≤—ã–±–æ—Ä–æ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            await bot.delete_message(user_id, call.message.message_id)

            await generateImagesInHandler(
                prompt,
                call.message,
                state,
                user_id,
                is_test_generation,
                setting_number,
            )

            await state.update_data(prompt_exist=False)
        else:
            await editMessageOrAnswer(
                call,
                text.GET_SETTINGS_SUCCESS_TEXT,
            )
            await state.set_state(StartGenerationState.write_prompt_for_images)

    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã, —Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤ —Ä–∞–±–æ—á–µ–º —Ä–µ–∂–∏–º–µ
    elif generations_type == "work":
        await editMessageOrAnswer(
            call,
            text.CHOOSE_WRITE_PROMPT_TYPE_SUCCESS_TEXT,
            reply_markup=start_generation_keyboards.writePromptTypeKeyboard(),
        )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞
async def choose_writePrompt_type(
    call: types.CallbackQuery,
    state: FSMContext,
):
    # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø: one –∏–ª–∏ multi
    prompt_type = call.data.split("|")[1]
    await state.update_data(writePrompt_type=prompt_type)

    if prompt_type == "one":
        # –û–¥–∏–Ω –ø—Ä–æ–º–ø—Ç –Ω–∞ –≤—Å–µ –º–æ–¥–µ–ª–∏
        await editMessageOrAnswer(
            call,
            text.GET_ONE_PROMPT_GENERATION_SUCCESS_TEXT,
            reply_markup=start_generation_keyboards.onePromptGenerationChooseTypeKeyboard(),
        )
        return

    state_data = await state.get_data()
    setting_number = state_data.get("setting_number", 1)

    # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã –º–æ–¥–µ–ª–µ–π
    if setting_number == "all":
        # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–æ all ‚Äî –±–µ—Ä—ë–º –≤—Å–µ –º–æ–¥–µ–ª–∏
        all_data_arrays = getAllDataArrays()
        start_index = 1
        end_index = sum(len(setting) for setting in all_data_arrays)
    else:
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        all_data_arrays = getAllDataArrays()
        logger.info([len(arr) for arr in all_data_arrays])
        setting_index = int(setting_number) - 1

        # –°—á–∏—Ç–∞–µ–º —Å–º–µ—â–µ–Ω–∏–µ –∫–∞–∫ —Å—É–º–º—É –¥–ª–∏–Ω –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–µ—Ç–æ–≤
        offset = sum(len(arr) for arr in all_data_arrays[:setting_index])

        # –î–ª–∏–Ω–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–µ—Ç–∞
        setting_length = len(all_data_arrays[setting_index])

        start_index = offset + 1
        end_index = offset + setting_length

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ —Å—Ç–µ–π—Ç
    await state.update_data(valid_model_indexes_range=(start_index, end_index))

    await editMessageOrAnswer(
        call,
        text.WRITE_PROMPTS_FOR_MODELS_TEXT.format(start_index, end_index),
    )
    await state.set_state(StartGenerationState.write_multi_prompts_for_models)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ "–∏–Ω–¥–µ–∫—Å: –ø—Ä–æ–º–ø—Ç" –¥–ª—è —Ç–µ–∫—É—â–µ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
async def write_prompts_for_models(message: types.Message, state: FSMContext):
    text_input = message.text.strip()
    matches = PROMPT_BY_INDEX_PATTERN.findall(text_input)

    if not matches:
        await safe_send_message(
            text.EMPTY_MATCHES_WRITE_PROMPTS_TEXT,
            message,
        )
        return

    state_data = await state.get_data()
    valid_range = state_data.get("valid_model_indexes_range", (1, 100))
    start_index, end_index = valid_range
    user_id = message.from_user.id
    expected_count = end_index - start_index + 1
    setting_number = state_data.get("setting_number", "1")

    model_prompts = {}
    for index_str, prompt in matches:
        if not index_str.isdigit():
            continue
        index = int(index_str)
        if not (start_index <= index <= end_index):
            await safe_send_message(
                text.MODEL_NOT_FOUND_TEXT.format(index),
                message,
            )
            return
        model_prompts[str(index)] = prompt.strip()

    if len(model_prompts) != expected_count:
        await safe_send_message(
            f"‚ö†Ô∏è –ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å <b>—Ä–æ–≤–Ω–æ {expected_count}</b> –ø—Ä–æ–º–ø—Ç–æ–≤ (–∞ –Ω–µ {len(model_prompts)}).",
            message,
        )
        return

    data_for_update = {
        f"{getModelNameByIndex(str(index))}": prompt
        for index, prompt in model_prompts.items()
    }
    await appendDataToStateArray(
        state,
        "model_prompts_for_generation",
        data_for_update,
        unique_keys=("model_name"),
    )

    await safe_send_message(
        "‚úÖ –ü—Ä–æ–º–ø—Ç—ã –ø–æ–ª—É—á–µ–Ω—ã. –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...",
        message,
    )

    try:
        await generateImagesInHandler(
            prompt=model_prompts,
            message=message,
            state=state,
            user_id=user_id,
            is_test_generation=False,
            setting_number=setting_number,
            with_randomizer=False,
        )
    except Exception:
        await safe_send_message("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", message)
        return

    await safe_send_message("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞", message)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –æ–¥–Ω–∏–º –ø—Ä–æ–º–ø—Ç–æ–º
async def chooseOnePromptGenerationType(
    call: types.CallbackQuery,
    state: FSMContext,
):
    one_prompt_generation_type = call.data.split("|")[1]

    if one_prompt_generation_type == "static":
        await editMessageOrAnswer(
            call,
            text.GET_STATIC_PROMPT_TYPE_SUCCESS_TEXT,
        )
        await state.set_state(StartGenerationState.write_prompt_for_images)

    elif one_prompt_generation_type == "random":
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ —Ä–∞–Ω–¥–æ–º–∞–π–∑–µ—Ä–µ
        await state.update_data(variable_names_for_randomizer=[])
        await state.update_data(variable_name_values=[])
        await editMessageOrAnswer(
            call,
            text.GET_RANDOM_PROMPT_TYPE_SUCCESS_TEXT,
            reply_markup=randomizer_keyboards.randomizerKeyboard([]),
        )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞
async def write_prompt(message: types.Message, state: FSMContext):
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    prompt = message.text
    user_id = message.from_user.id
    state_data = await state.get_data()
    is_test_generation = state_data.get("generations_type", "") == "test"
    await state.update_data(prompt_for_images=prompt)

    await state.set_state(None)

    # –ï—Å–ª–∏ –≤ —Å—Ç–µ–π—Ç–µ –µ—Å—Ç—å –Ω–æ–º–µ—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–∏
    if "setting_number" in state_data:
        setting_number = state_data.get("setting_number", 1)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        await generateImagesInHandler(
            prompt,
            message,
            state,
            user_id,
            is_test_generation,
            setting_number,
        )
    else:
        model_indexes = state_data.get("model_indexes_for_generation", [])
        logger.info(f"–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {model_indexes}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        await generateImagesInHandler(
            prompt,
            message,
            state,
            user_id,
            is_test_generation,
            "individual",
        )


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
async def select_image(call: types.CallbackQuery, state: FSMContext):
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≤—ã–±–æ—Ä–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    await editMessageOrAnswer(
        call,
        text.SELECT_IMAGE_PROGRESS_TEXT,
    )

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ä–∞–±–æ—Ç—ã –∏ –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    model_name = call.data.split("|")[1]
    setting_number = call.data.split("|")[2]
    image_index = call.data.split("|")[3]

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–∏
    data = await getDataByModelName(model_name)

    # –£–¥–∞–ª—è–µ–º –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—É
    await deleteMessageFromState(
        state,
        "imageGeneration_mediagroup_messages_ids",
        model_name,
        call.message.chat.id,
    )

    try:
        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞–≤–µ–Ω "regenerate", —Ç–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if image_index == "regenerate":
            return await regenerateImage(
                model_name,
                call,
                state,
                setting_number,
            )

        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞–≤–µ–Ω "regenerate_with_new_prompt", —Ç–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        elif image_index == "regenerate_with_new_prompt":
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–µ–π—Ç –¥–ª—è –≤–≤–æ–¥–∞ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            await state.update_data(model_name_for_regenerate_image=model_name)
            await state.update_data(
                setting_number_for_regenerate_image=setting_number,
            )

            await state.set_state(
                StartGenerationState.write_new_prompt_for_regenerate_image,
            )

            # –ü—Ä–æ—Å–∏–º –≤–≤–µ—Å—Ç–∏ –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            write_new_prompt_for_regenerate_message = (
                await editMessageOrAnswer(call, text.WRITE_NEW_PROMPT_TEXT)
            )
            await state.update_data(
                write_new_prompt_message_id=write_new_prompt_for_regenerate_message.message_id,
            )
            return

        image_index = int(image_index)

        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—â–µ–º –≤–æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∞—Å—Å–∏–≤–∞—Ö
        if data is None:
            all_data_arrays = getAllDataArrays()
            for arr in all_data_arrays:
                data = next(
                    (d for d in arr if d["model_name"] == model_name),
                    None,
                )
                if data is not None:
                    break

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ id –ø–∞–ø–∫–∏ –¥–ª—è –≤–∏–¥–µ–æ
        await state.update_data(model_name=model_name)

        try:
            logger.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            await process_image(
                call,
                state,
                model_name,
                image_index,
            )
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –≤ process_image")
            await editMessageOrAnswer(
                call,
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}",
            )

    except Exception as e:
        traceback.print_exc()
        model_name_index = getModelNameIndex(model_name)

        await editMessageOrAnswer(
            call,
            text.GENERATE_IMAGE_ERROR_TEXT.format(
                model_name,
                model_name_index,
                e,
            ),
        )
        raise e


async def write_model_name_for_generation(
    message: types.Message,
    state: FSMContext,
):
    text_input = message.text.strip()

    # 1. –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: 1 - —Ç–µ–∫—Å—Ç
    matches = PROMPT_BY_INDEX_PATTERN.findall(text_input)

    if matches:
        model_prompts = {}
        for index, prompt in matches:
            if not index.isdigit():
                continue
            if not (1 <= int(index) <= 100):
                await safe_send_message(
                    text=text.MODEL_NOT_FOUND_TEXT.format(index),
                    message=message,
                )
                return
            model_prompts[str(index)] = prompt.strip()

        data_for_update = {
            f"{getModelNameByIndex(str(index))}": prompt
            for index, prompt in model_prompts.items()
        }
        await appendDataToStateArray(
            state,
            "model_prompts_for_generation",
            data_for_update,
        )

        await safe_send_message(
            text="‚úÖ –ü—Ä–æ–º–ø—Ç—ã –ø–æ –º–æ–¥–µ–ª—è–º –ø–æ–ª—É—á–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...",
            message=message,
        )

        await generateImagesInHandler(
            prompt=model_prompts,
            message=message,
            state=state,
            user_id=message.from_user.id,
            is_test_generation=False,
            setting_number="individual",
        )
        return

    # 2. –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–≤–µ–¥—ë–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–º
    if not message.text.isdigit():
        await safe_send_message(
            text=text.NOT_NUMBER_TEXT,
            message=message,
        )
        return

    model_indexes = message.text.split(",")
    if len(model_indexes) == 1:
        model_indexes = [message.text]

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    all_data_arrays = getAllDataArrays()
    all_data_arrays_length = sum(len(arr) for arr in all_data_arrays)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–∞–∫–∏–µ –º–æ–¥–µ–ª–∏
    for model_index in model_indexes:
        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –±–æ–ª—å—à–µ —á–∏—Å–ª–∞ –º–æ–¥–µ–ª–µ–π –∏–ª–∏ –º–µ–Ω—å—à–µ 1, —Ç–æ –ø—Ä–æ—Å–∏–º –≤–≤–µ—Å—Ç–∏ –¥—Ä—É–≥–æ–π –∏–Ω–¥–µ–∫—Å
        if int(model_index) > all_data_arrays_length or int(model_index) < 1:
            await safe_send_message(
                text=text.MODEL_NOT_FOUND_TEXT.format(model_index),
                message=message,
            )
            return

    await state.update_data(model_indexes_for_generation=model_indexes)
    # –í—Å—ë –≤–∞–ª–∏–¥–Ω–æ ‚Äî –∏–¥—ë–º –ø–æ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
    await state.update_data(
        model_indexes_for_generation=model_indexes,
    )

    await state.set_state(None)
    await safe_send_message(
        text=text.GET_MODEL_INDEX_SUCCESS_TEXT
        if len(model_indexes) == 1
        else text.GET_MODEL_INDEXES_SUCCESS_TEXT,
        message=message,
    )

    await state.set_state(StartGenerationState.write_prompt_for_images)


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–≤–æ–¥–∞ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
async def write_new_prompt_for_regenerate_image(
    message: types.Message,
    state: FSMContext,
):
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    prompt = message.text
    if not prompt:
        await safe_send_message(
            text=text.EMPTY_PROMPT_TEXT,
            message=message,
        )
        return

    state_data = await state.get_data()
    is_test_generation = state_data.get("generations_type", "") == "test"
    model_name = state_data.get("model_name_for_regenerate_image", "")
    setting_number = state_data.get("setting_number_for_regenerate_image", 1)
    user_id = message.from_user.id

    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    await message.delete()

    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞
    write_new_prompt_message_id = state_data.get(
        "write_new_prompt_message_id",
        None,
    )
    if write_new_prompt_message_id:
        try:
            await bot.delete_message(user_id, write_new_prompt_message_id)
        except Exception as e:
            logger.error(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ"
                f"–Ω–æ–≤–æ–º—É –ø—Ä–æ–º–ø—Ç—É {write_new_prompt_message_id} - {e}",
            )

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –≤ —Å—Ç–µ–π—Ç –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
    data_for_update = {f"{model_name}": prompt}
    await appendDataToStateArray(
        state,
        "prompts_for_regenerated_models",
        data_for_update,
    )

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å –º–æ–¥–µ–ª–∏
    model_name_index = getModelNameIndex(model_name)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    modified_prompt = prompt[:30] + "..." if len(prompt) > 30 else prompt
    regenerate_progress_message = await safe_send_message(
        text=text.REGENERATE_IMAGE_WITH_NEW_PROMPT_TEXT.format(
            model_name,
            model_name_index,
            modified_prompt,
        ),
        message=message,
    )

    await state.set_state(None)

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –º–æ–¥–µ–ª–∏
    data = await getDataByModelName(model_name)

    await generateImageBlock(
        data,
        regenerate_progress_message.message_id,
        state,
        user_id,
        setting_number,
        prompt,
        is_test_generation,
        False,
        chat_id=message.chat.id,
    )
    await regenerate_progress_message.delete()


# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
def hand_add():
    router.callback_query.register(
        choose_generations_type,
        lambda call: call.data.startswith("generations_type"),
    )

    router.callback_query.register(
        choose_generation_mode,
        lambda call: call.data.startswith("generation_mode"),
    )

    router.callback_query.register(
        choose_setting,
        lambda call: call.data.startswith("select_setting"),
    )

    router.callback_query.register(
        choose_writePrompt_type,
        lambda call: call.data.startswith("write_prompt_type"),
    )

    router.callback_query.register(
        chooseOnePromptGenerationType,
        lambda call: call.data.startswith("one_prompt_generation_type"),
    )

    router.message.register(
        write_prompt,
        StateFilter(StartGenerationState.write_prompt_for_images),
    )

    router.callback_query.register(
        select_image,
        lambda call: call.data.startswith("select_image"),
    )

    router.message.register(
        write_model_name_for_generation,
        StateFilter(StartGenerationState.write_model_name_for_generation),
    )

    router.message.register(
        write_new_prompt_for_regenerate_image,
        StateFilter(
            StartGenerationState.write_new_prompt_for_regenerate_image,
        ),
    )
    router.message.register(
        write_prompts_for_models,
        StartGenerationState.write_multi_prompts_for_models,
    )
